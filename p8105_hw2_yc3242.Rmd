---
title: "p8105_hw2_yc3242"
author: "Youn Kyeong Chang (uni# yc3242)"
date: "October 3, 2018"
output: github_document
---

I used the tidyverse library through the whole problem set.

```{r}
library(tidyverse)
```


# Problem 1

First, I loaded and cleaned dataset for problem 1. 

```{r data import}
nyc_data = 
  read_csv(file = "./hw2_data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line:entry, vending, ada) %>% 
  mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE))
```

This NYC Transit data (`nyc_data`) is composed of *line, station name, its latitude and longitude, routes it serves, entrance type, whether or not you can enter the station, presence of ticket vending machine*, and *ADA compliance*. These variables were selected from `NYC_Transit_Subway_Entrance_And_Exit_Data.csv` original dataset which was followed by `clean_names()` function in the janitor library. After selecting variables process, `entry` variable was converted from character variable to logical variable. The size of the NYC Transit data is `r nrow(nyc_data)` rows and `r ncol(nyc_data)` columns. These data are not tidy because columns are values not variables and there are many duplicated rows. 

To remove duplicated rows, I used `distinct()` function as below:

```{r}
nyc_data = distinct(nyc_data)
```

The **size** of the NYC Transit data is now `r nrow(nyc_data)` rows and `r ncol(nyc_data)` columns.

### Questions

**1.1. How many distinct stations are there?**

```{r distinct_stations}
nyc_data %>% 
  distinct(line, station_name, .keep_all = TRUE) %>% 
  count()
```

There are **465** distinct stations.


**1.2. How many stations are ADA compliant?**

```{r ada}
nyc_data %>% 
  distinct(line, station_name, .keep_all = TRUE) %>% 
  filter(ada == TRUE) %>% 
  count(ada)
```

There are **84** ADA compliant stations.


**1.3. What proportion of station entrances / exits without vending allow entrance?**

```{r proportion}
nyc_data %>% 
  filter(vending == "NO") %>% 
  summarise(mean(entry == TRUE))
```

The proportion of station entrances / exits without vending allow entrance is **0.385**.


**1.4. How many distinct stations serve the A train?**

To answer the questions 1.4. and 1.5., I reformatted data as below so that route number and route name are distinct variables.

```{r reformat}
reform_nyc_data = 
  nyc_data %>%
  gather(key = "route", value = "route_name", route1:route11) %>%  # gather spreading route variables
  separate(route, into = c("remove", "route_number"), sep = 5) %>% 
  select(-remove)
```

And then, I calculated distinct stations serve the A train.
```{r distinct_A}
reform_nyc_data %>% 
  distinct(line, station_name, route_name) %>%
  filter(route_name == "A") %>%
  count()
```

There are **60** distinct stations serve A train.


**1.5. Of the stations that serve the A train, how many are ADA compliant?**

```{r ada_A}
reform_nyc_data %>% 
  distinct(line, station_name, route_name, .keep_all = TRUE) %>%
  filter(route_name == "A", ada == "TRUE") %>%
  count()
```

There are **17** ADA compliant distinct stations serve A train.


# Problem 2

I I used the readxl library to read `xlsx` file for problem 2. 

```{r}
library(readxl)
```


### Mr. Trash Wheel

I read and clean the Mr. Trash Wheel sheet as follows.

```{r trash_import}
trash_data = 
  read_excel(path = "./hw2_data/HealthyHarborWaterWheelTotals2018-7-28.xlsx",
                     sheet = 1, range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>%                              # use reasonable variable names
  filter(!is.na(dumpster)) %>%                            # omit NA data
  mutate(sports_balls = as.integer(round(sports_balls)))  # round and convert sports_ball
```

* The **number of observations** is `r nrow(trash_data)`.
* I think the **key variables** are `month` and `year` since in general, we can analyze the total amount of trash or each kind of trash by them.
* The **median** number of sports balls in a dumpster in 2016 is `r trash_data %>% filter(year == 2016) %>% summarise(median(sports_balls))`.

### Precipiation data

I read and clean precipitation data for 2016.

```{r precip_2016_import}
precip_2016 = 
  read_excel(path = "./hw2_data/HealthyHarborWaterWheelTotals2018-7-28.xlsx",
                     sheet = 5, skip = 1) %>% 
  janitor::clean_names() %>%    
  rename(total_precip = total) %>%                    # use reasonable variable names
  filter(!is.na(month) & !is.na(total_precip)) %>%    # omit NA data
  mutate(year = 2016)                                 # add a variable year
```

Next, I read and clean precipitation data for 2017.

```{r precip_2017_import}
precip_2017 = 
  read_excel(path = "./hw2_data/HealthyHarborWaterWheelTotals2018-7-28.xlsx",
                     sheet = 4, skip = 1) %>% 
  janitor::clean_names() %>% 
  rename(total_precip = total) %>%                  # use reasonable variable names
  filter(!is.na(month) & !is.na(total_precip)) %>%  # omit NA data
  mutate(year = 2017)                               # add a variable year
```

And then, I combined these datasets and converted month to a character variable.

```{r precip_combine}
precip_data = bind_rows(precip_2016, precip_2017) %>% 
              mutate(month = month.name[month])
```

* The **number of observations** is `r nrow(precip_data)`.
* In this case, `month` and `year` can be considered as **key variables** since, for example, we can see the trends of precipitation by month and compare the amount of precipitation in years.
* The **total precipitation in 2017** is `r sum(precip_2017$total_precip)`(in).

